{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3a-ZWVB-YLl"
      },
      "outputs": [],
      "source": [
        "!pip install paddlepaddle\n",
        "!pip install \"paddleocr>=2.0.1\"\n",
        "!pip install Pillow numpy opencv-python transformers nltk langchain_google_genai langchain\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyC29gObkycJDBjVkEWjhJoJO-HVB0pC00E\""
      ],
      "metadata": {
        "id": "Mqu2ni8JBRNV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from paddleocr import PaddleOCR\n",
        "from PIL import Image\n",
        "import datetime\n",
        "import logging\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import google.generativeai as genai\n",
        "\n",
        "class TweetAnalyzer:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the Tweet Analyzer with necessary models and configurations.\"\"\"\n",
        "        # # Load environment variables\n",
        "        # load_dotenv()\n",
        "\n",
        "        # Initialize Google API\n",
        "        GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
        "        if not GOOGLE_API_KEY:\n",
        "            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
        "\n",
        "        genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "        # Initialize Gemini Pro\n",
        "        self.llm = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
        "\n",
        "        # Initialize OCR\n",
        "        try:\n",
        "            self.ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to initialize PaddleOCR: {e}\")\n",
        "            self.ocr = None\n",
        "\n",
        "        # Configure logging\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        # Initialize prompt templates\n",
        "        self.init_prompts()\n",
        "\n",
        "    def init_prompts(self):\n",
        "        \"\"\"Initialize prompt templates for different analysis tasks.\"\"\"\n",
        "\n",
        "        self.analysis_prompt = PromptTemplate(\n",
        "            input_variables=[\"tweet_text\"],\n",
        "            template=\"\"\"\n",
        "            Analyze this tweet content and provide:\n",
        "            1. A concise summary\n",
        "            2. Main topics discussed\n",
        "            3. Key points and insights\n",
        "            4. Sentiment and tone\n",
        "            5. Any relevant context or background information\n",
        "            6. Potential implications or significance\n",
        "            7 . give me a suggested reply based on thread (make another section for this)\n",
        "            Tweet content: {tweet_text}\n",
        "\n",
        "            Provide the analysis in a clear, structured format.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        self.metadata_prompt = PromptTemplate(\n",
        "            input_variables=[\"tweet_text\"],\n",
        "            template=\"\"\"\n",
        "            Extract and analyze the following metadata from this tweet:\n",
        "            1. Mentioned usernames (starting with @)\n",
        "            2. Hashtags (starting with #)\n",
        "            3. URLs\n",
        "            4. Any dates or timestamps mentioned\n",
        "            5. Any locations mentioned\n",
        "            6. Any organizations referenced\n",
        "\n",
        "            Tweet content: {tweet_text}\n",
        "\n",
        "            Format the response as a structured list of findings.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    def extract_text_from_image(self, image_path: str) -> str:\n",
        "        \"\"\"Extract text from tweet screenshot using PaddleOCR.\"\"\"\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                raise ValueError(\"Could not read image file\")\n",
        "\n",
        "            result = self.ocr.ocr(image)\n",
        "\n",
        "            text_results = []\n",
        "            if result[0]:\n",
        "                for line in result[0]:\n",
        "                    text_results.append(line[1][0])\n",
        "\n",
        "            full_text = ' '.join(text_results)\n",
        "            return full_text.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error extracting text from image: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def preprocess_image(self, image_path: str) -> np.ndarray:\n",
        "        \"\"\"Preprocess the image for better OCR results.\"\"\"\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "            denoised = cv2.fastNlMeansDenoising(binary)\n",
        "            return denoised\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error preprocessing image: {e}\")\n",
        "            return None\n",
        "\n",
        "    async def analyze_with_gemini(self, text: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Analyze tweet content using Gemini Pro through Langchain.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Create analysis chain\n",
        "            analysis_chain = LLMChain(llm=self.llm, prompt=self.analysis_prompt)\n",
        "            metadata_chain = LLMChain(llm=self.llm, prompt=self.metadata_prompt)\n",
        "\n",
        "            # Run analysis\n",
        "            analysis_result = await analysis_chain.arun(tweet_text=text)\n",
        "            metadata_result = await metadata_chain.arun(tweet_text=text)\n",
        "\n",
        "            return {\n",
        "                \"analysis\": analysis_result,\n",
        "                \"metadata\": metadata_result\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error in Gemini analysis: {e}\")\n",
        "            return {\n",
        "                \"analysis\": \"Error in analysis\",\n",
        "                \"metadata\": \"Error in metadata extraction\"\n",
        "            }\n",
        "\n",
        "    async def generate_report(self, image_path: str) -> Dict:\n",
        "        \"\"\"Generate comprehensive analysis report for a tweet screenshot.\"\"\"\n",
        "        report = {\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"source_image\": image_path,\n",
        "            \"extracted_text\": None,\n",
        "            \"analysis\": None,\n",
        "            \"error\": None\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Preprocess image\n",
        "            preprocessed_image = self.preprocess_image(image_path)\n",
        "            if preprocessed_image is None:\n",
        "                raise ValueError(\"Failed to preprocess image\")\n",
        "\n",
        "            # Extract text\n",
        "            text = self.extract_text_from_image(image_path)\n",
        "            if not text:\n",
        "                raise ValueError(\"No text could be extracted from image\")\n",
        "            report[\"extracted_text\"] = text\n",
        "\n",
        "            # Analyze with Gemini\n",
        "            analysis_results = await self.analyze_with_gemini(text)\n",
        "            report[\"analysis\"] = analysis_results\n",
        "\n",
        "        except Exception as e:\n",
        "            report[\"error\"] = str(e)\n",
        "            self.logger.error(f\"Error generating report: {e}\")\n",
        "\n",
        "        return report\n",
        "\n",
        "    def format_report(self, report: Dict) -> str:\n",
        "        \"\"\"Format the analysis report into a readable string.\"\"\"\n",
        "        if report.get(\"error\"):\n",
        "            return f\"Error analyzing tweet: {report['error']}\"\n",
        "\n",
        "        formatted_report = []\n",
        "        formatted_report.append(\"üê¶ Tweet Analysis Report\")\n",
        "        formatted_report.append(\"=\" * 50)\n",
        "\n",
        "        # Original Text\n",
        "        formatted_report.append(\"\\nüìù Extracted Text:\")\n",
        "        formatted_report.append(report[\"extracted_text\"])\n",
        "        formatted_report.append(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "        # Gemini Analysis\n",
        "        if report[\"analysis\"]:\n",
        "            formatted_report.append(\"\\nü§ñ Thread Analysis:\")\n",
        "            formatted_report.append(report[\"analysis\"][\"analysis\"])\n",
        "            formatted_report.append(\"\\n\" + \"-\" * 30)\n",
        "\n",
        "            formatted_report.append(\"\\nüìä Metadata Analysis:\")\n",
        "            formatted_report.append(report[\"analysis\"][\"metadata\"])\n",
        "\n",
        "        return \"\\n\".join(formatted_report)\n",
        "\n",
        "async def main():\n",
        "    \"\"\"Main function to demonstrate usage of the TweetAnalyzer class.\"\"\"\n",
        "    # Initialize analyzer\n",
        "    analyzer = TweetAnalyzer()\n",
        "\n",
        "    # Get image path from user\n",
        "    image_path = \"test2.png\"\n",
        "\n",
        "    # Generate and display report\n",
        "    report = await analyzer.generate_report(image_path)\n",
        "    formatted_report = analyzer.format_report(report)\n",
        "    print(\"\\n\", formatted_report)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import asyncio\n",
        "    await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl9Q0QOGAu63",
        "outputId": "6e78380c-8128-4b18-fc06-c663e35dd15e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024/11/24 07:31:16] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.10/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
            "[2024/11/24 07:31:19] ppocr DEBUG: dt_boxes num : 62, elapsed : 0.37656092643737793\n",
            "[2024/11/24 07:31:19] ppocr DEBUG: cls num  : 62, elapsed : 0.1714468002319336\n",
            "[2024/11/24 07:31:35] ppocr DEBUG: rec_res num  : 62, elapsed : 16.528851747512817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-4de400297c0b>:121: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  analysis_chain = LLMChain(llm=self.llm, prompt=self.analysis_prompt)\n",
            "<ipython-input-2-4de400297c0b>:125: LangChainDeprecationWarning: The method `Chain.arun` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~ainvoke` instead.\n",
            "  analysis_result = await analysis_chain.arun(tweet_text=text)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " üê¶ Tweet Analysis Report\n",
            "==================================================\n",
            "\n",
            "üìù Extracted Text:\n",
            "Post Marc Lou0 emarc_louvion I was a virgin, an hour ago. I've never blocked anyone after 3 years on Twitter. But my feed in the past 30 days is made of developers who think the world can be fixed with more tests. Dozens of people try to screw my sites every day. And they claim a CRITICALVULNERABILITY ISSUE because they could bypass a paywall Or add a special character to their usemame So fuck it. I blocked people who yap instead of shipping.. T want to see posts of indie makers who build and print money. KEEP SHIPPING 6:15 PM - Oct 21, 2024 - 720.9KViews  371 159 1.7K 333 Post your reply Reply LefterisX @ greekdubliner - Oct 22 Thanks for inspiring us Marc. Alresdy shipped two product usingShipFast 1 C O1 532 1 Fekri@fekdsoui - Oct 21 +** yes, i actually posted about this too because it's all i'm seeingon my timeline some talk. others ship. it's clear who is who 3Fekrifekdsoui - Oct 21 there are two types of people in indiehacking right now:. - the ones who criticize, tear others down, and never miss a chance to hate on other founders - the ones who build, ship, and help others out... Show more  4 t 1 16 IlI 9.1K Thorr codinsonn.dey @ codinsonn - Oct 21 grain of truth to some of these issues beingreported? critical flows where security is paramount. Q 1 C 7 r3.5K\n",
            "\n",
            "==================================================\n",
            "\n",
            "ü§ñ Thread Analysis:\n",
            "**1. Concise Summary**\n",
            "\n",
            "Marc Louvion expresses frustration with developers who prioritize testing over building and shipping products. He has blocked individuals who engage in excessive criticism and instead wants to focus on seeing posts from indie makers who are actively building and generating revenue.\n",
            "\n",
            "**2. Main Topics Discussed**\n",
            "\n",
            "* Criticism vs. building in indie hacking\n",
            "* The importance of shipping products\n",
            "* The value of focusing on revenue generation\n",
            "\n",
            "**3. Key Points and Insights**\n",
            "\n",
            "* Louvion believes that excessive testing can hinder progress and that it is more important to focus on building and shipping products.\n",
            "* He emphasizes the value of indie makers who are actively building and generating revenue.\n",
            "* Louvion suggests that those who criticize others without contributing to the community are not true indie hackers.\n",
            "\n",
            "**4. Sentiment and Tone**\n",
            "\n",
            "* Louvion's tone is frustrated and critical towards those who prioritize testing over building.\n",
            "* He is also passionate about the importance of shipping products and generating revenue.\n",
            "\n",
            "**5. Relevant Context or Background Information**\n",
            "\n",
            "* Indie hacking is a movement that emphasizes building and shipping products independently.\n",
            "* There has been a recent trend of developers focusing on testing and security vulnerabilities, which Louvion believes has become excessive.\n",
            "\n",
            "**6. Potential Implications or Significance**\n",
            "\n",
            "* Louvion's tweet could spark a debate about the balance between testing and building in indie hacking.\n",
            "* It could also encourage indie makers to focus more on shipping products and generating revenue.\n",
            "\n",
            "**7. Suggested Reply**\n",
            "\n",
            "**@marc_louvion**\n",
            "\n",
            "I agree with you, Marc. It's important to find a balance between testing and building. While testing is essential for ensuring the quality of our products, it shouldn't become an obstacle to progress. Let's focus on shipping products that solve real problems and make a difference in the world.\n",
            "\n",
            "#IndieHacking #BuildAndShip #RevenueGeneration\n",
            "\n",
            "------------------------------\n",
            "\n",
            "üìä Metadata Analysis:\n",
            "**Metadata Analysis:**\n",
            "\n",
            "**1. Mentioned usernames:**\n",
            "- @emarc_louvion\n",
            "- @greekdubliner\n",
            "- @fekdsoui\n",
            "- @codinsonn\n",
            "\n",
            "**2. Hashtags:**\n",
            "- None\n",
            "\n",
            "**3. URLs:**\n",
            "- None\n",
            "\n",
            "**4. Dates or timestamps:**\n",
            "- Oct 21, 2024\n",
            "- Oct 22\n",
            "\n",
            "**5. Locations:**\n",
            "- None\n",
            "\n",
            "**6. Organizations referenced:**\n",
            "- ShipFast\n"
          ]
        }
      ]
    }
  ]
}